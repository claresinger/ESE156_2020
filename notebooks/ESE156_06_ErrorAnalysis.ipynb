{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "#### ESE156 2020,  6th notebook, Christian Frankenberg \n",
    "\n",
    "Based on our previous \"TCCON example\", we will work through some linear error analysis here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our tools (you might need to add packages, see file)\n",
    "include(\"../scripts/ese156_tools.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Define file and lat/lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"files/MERRA300.prod.assim.inst6_3d_ana_Nv.20150613.hdf.nc4\"\n",
    "timeIndex = 2 # There is 00, 06, 12 and 18 in UTC, i.e. 6 hourly data stacked together\n",
    "\n",
    "# What latitude do we want? \n",
    "myLat = 34.1377;\n",
    "myLon = -118.1253;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read profile (and generate dry/wet VCDs per layer)\n",
    "profile_caltech_hr = read_atmos_profile(file, myLat, myLon, timeIndex);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Define HITRAN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed the limits here now: \n",
    "\n",
    "# Minimum wavenumber\n",
    "ν_min  = 6280.0\n",
    "# Maximum wavenumber\n",
    "ν_xmax = 6420.0\n",
    "\n",
    "co2_par = CrossSection.read_hitran(\"files/hitran_molec_id_2_CO2.par\", mol=2, iso=1, ν_min=ν_min, ν_max=ν_xmax);\n",
    "ch4_par = CrossSection.read_hitran(\"files/hitran_molec_id_6_CH4.par\", mol=6, iso=1, ν_min=ν_min, ν_max=ν_xmax);\n",
    "h2o_par = CrossSection.read_hitran(\"files/hitran_molec_id_1_H2O.par\", mol=1, iso=1, ν_min=ν_min, ν_max=ν_xmax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_voigt   = make_hitran_model(co2_par, Voigt(), wing_cutoff=10)\n",
    "h2o_voigt   = make_hitran_model(h2o_par, Voigt(), wing_cutoff=10)\n",
    "ch4_voigt   = make_hitran_model(ch4_par, Voigt(), wing_cutoff=10)\n",
    "\n",
    "hitran_array = [co2_voigt, h2o_voigt, ch4_voigt];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Define model resolution and compute all cross sections for profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 0.005\n",
    "ν = 6300:res:6400\n",
    "σ_matrix_hr = compute_profile_crossSections(profile_caltech_hr, hitran_array , ν);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions, group layers together to get roughly layers of equal pressure difference:\n",
    "n_layers = 15\n",
    "profile_caltech, σ_matrix = reduce_profile(n_layers, profile_caltech_hr, σ_matrix_hr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define concentration profile:\n",
    "#nL = length(profile_caltech.T)\n",
    "nL = length(profile_caltech_hr.T)\n",
    "\n",
    "vmr_co2 = zeros(nL) .+ 400e-6\n",
    "vmr_ch4 = zeros(nL) .+ 2e-6\n",
    "vmr_h2o = profile_caltech_hr.vcd_h2o ./ profile_caltech_hr.vcd_dry\n",
    "vmrs = [vmr_co2, vmr_h2o, vmr_ch4 ];\n",
    "\n",
    "# Define a polynomial scaling\n",
    "p = Polynomial([2,-0.1,0.00003]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Define Instrument models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Instrument, TCCON specs\n",
    "FWHM = 0.02  # 0.2cm-1 resolution\n",
    "Δν = 0.01\n",
    "tccon = KernelInstrument(gaussian_kernel(FWHM, res), collect(6300:Δν:6400));\n",
    "\n",
    "# Define an Instrument, OCO-2 specs\n",
    "FWHM = 0.4  # 0.2cm-1 resolution\n",
    "Δν = 0.1\n",
    "oco2 = KernelInstrument(gaussian_kernel(FWHM, res), collect(6300:Δν:6400));\n",
    "\n",
    "# Define an Instrument, SCIAMACHY specs\n",
    "FWHM = 4.0  # 0.2cm-1 resolution\n",
    "Δν = 1.0\n",
    "sciamachy = KernelInstrument(gaussian_kernel(FWHM, res), collect(6300:Δν:6400));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in disk-centered solar spectrum:\n",
    "sun = readdlm(\"files/solar_merged_20160127_600_26316_100.out\")\n",
    "f_solar = CubicSplineInterpolation(sun[1,1]:sun[2,1]-sun[1,1]:sun[end,1], sun[:,2])\n",
    "Tsolar = f_solar(ν)\n",
    "\n",
    "plot(ν, Tsolar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## How can we write this as a Forward Model F(x)?\n",
    "\n",
    "First, we need to decide what we need in the state vector. If we assume that the temperature and pressure profile is well known, then these are \"known\" parameters and not part of the state vector. That probably leaves us with the polynomial term as well as the trace gas concentrations.\n",
    "\n",
    "## Computing Forward model and Jacobian K\n",
    "What we are trying to do now is to write a function that can evaluate the Forward model but also compute its Jacobian if needed. In principle, one could compute the Jacobian numerically but this would require evaluating the Forward model with a perturbed state vector (one for each) and choosing the right step-size to compute the derivative numerically \n",
    "$$\\frac{\\partial F(x)}{\\partial x_i} = \\frac{F(x+\\Delta x_i)-F(x)}{\\Delta x_i}$$\n",
    "or better a two-point formula:\n",
    "$$\\frac{\\partial F(x)}{\\partial x_i} = \\frac{F(x+\\Delta x_i)-F(x-\\Delta x_i)}{2\\Delta x_i}$$\n",
    "\n",
    "Let's go back to our forward model, which includes the computation of the transmission of the atmosphere along a slant light-path from the sun to the observer on the ground, multiplied with a low-order polynomial to account for any other effect such as scattering in the atmosphere, spectral shape of Black body of solar spectrum, detector sensitivity, etc. (it just bunches up all these effects without a real physical meaning here):\n",
    "$$F(x) = <I_o\\cdot\\exp\\left(-AMF\\cdot\\sum_{i=0}^n x_i\\cdot VCD^{dryAir}_i\\cdot \\sigma_i(\\nu)\\right)\\cdot \\sum_{i=n+1}^{n+1+polyDegree}x_i\\cdot \\nu^{i-(n+1)}>$$ \n",
    "with $x_{i\\dots n}$ being the the $VMRs$ and $x_{i+n\\dots n+1+polyDegree}$ the coefficients for the polynomial. The operator $<>$ denotes the instrument operator (instrument line shape ILS), including the convolution of the high resolution transmission and resampling to the detector wavenumber grid:\n",
    "$$<I>(\\nu_1) = \\int_{-\\infty}^{\\infty}I(\\nu)\\cdot ILS(\\nu_1-\\nu)d\\nu$$\n",
    "or in its discrete form\n",
    "$$<I>(\\nu_1) = \\sum_{\\nu=-\\nu_1-\\Delta}^{\\nu_1+\\Delta}I(\\nu)\\cdot ILS(\\nu_1-\\nu)\\,,$$\n",
    "where we can choose a width $\\Delta$ over which the convolution will be applied (typically just the range over which the ILS is finite). The above didn't yet include the resampling to the detector ($y$) grid but this is just an interpolation anyhow (a down-sampling from a higher resolution grid to the actual nmeasurement grid). If the ILS is not changing over the entire fitting range, we can make use of the convolution theorem, which states that under suitable conditions the Fourier transform of a convolution is the pointwise product of Fourier transforms (otherwise, we often need a bute-force convolution, which can cost time). \n",
    "\n",
    "What we need to compute as well is the Jacobian Matrix $K$, which is defined as the derivative of the forward model with respect to $x$:\n",
    "\n",
    "$$K = {dF(x) \\over dx} = \n",
    "\\left\\vert\\matrix{{\\partial F_1(x) \\over \\partial x_1} & {\\dots} & {\\partial F_1(x) \\over \\partial x_n} \\cr \n",
    "{\\vdots} & {\\ddots } & {\\vdots} \\cr \n",
    "{\\partial F_m(x) \\over \\partial x_1} & {\\dots} & {\\partial F_m(x) \\over \\partial x_n}}\\right\\vert\\,.$$\n",
    "\n",
    "In our simplified forward model, we can actually compute the derivatives analytically. For the state vector elements with a $VMR$, the derivative will be:\n",
    "$${\\partial F(x) \\over \\partial x_i} = <F(x)\\cdot -AMF \\cdot VCD^{dryAir}_i\\cdot \\sigma_i(\\nu)>$$\n",
    "\n",
    "From here on, we will try to use Automatic Differentiation tools though (https://en.wikipedia.org/wiki/Automatic_differentiation).\n",
    "Julia has tools for automatic differentation (even though you should be able to do this specific one still analytically without too much effort). However, there are current programming constraints, it has to be defined as single-valued functions (f(x); x=1D array) and return a 1D array), so let's try:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's concatenate the important parameters as state vector:\n",
    "# Make ABSOLUTELY sure you keep the order as in the σ_matrix!!\n",
    "𝐱 = [vmr_co2; vmr_h2o; vmr_ch4; p[:] ];\n",
    "@show size(𝐱)\n",
    "sza = 45.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then rewrite the forward model:\n",
    "function forward_model_x(𝐱     ;instrument=tccon, sza=sza, profile=profile_caltech_hr,σ_matrix=σ_matrix_hr, ν=ν, Tsolar=Tsolar)\n",
    "    FT = eltype(𝐱);\n",
    "    dims = size(σ_matrix)\n",
    "    vmrs = reshape(𝐱[1:(dims[2]*dims[3])],(dims[2],dims[3]) )\n",
    "    poly = Polynomial(𝐱[dims[2]*dims[3]+1:end])\n",
    "    \n",
    "    # Air Mass Factor\n",
    "    AMF = 1/cosd(sza)\n",
    "    \n",
    "    # Total sum of τ\n",
    "    ∑τ = zeros(FT,size(σ_matrix,1))\n",
    "    for i=1:size(vmrs,2)\n",
    "        ∑τ[:] += sum(σ_matrix[:,:,i] .* (vmrs[:,i] .* profile.vcd_dry)', dims=2)\n",
    "    end\n",
    "    # Transmission\n",
    "    T = Tsolar .* exp.(-AMF * ∑τ)\n",
    "    T_conv = conv_spectra(instrument, ν, T)\n",
    "    # x-axis for polynomial [-1,1], enables legendre later:\n",
    "    x_poly = rescale_x(instrument.ν_out)\n",
    "    return T_conv .* poly.(x_poly)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefine output\n",
    "result = DiffResults.JacobianResult(zeros(length(tccon.ν_out)),𝐱);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not yet happy about the speed here, likely due to a ton of allocations\n",
    "@time ForwardDiff.jacobian!(result, forward_model_x, 𝐱 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = DiffResults.jacobian(result)\n",
    "F = DiffResults.value(result)\n",
    "plot(tccon.ν_out,F )\n",
    "ylabel!(\"F(x)\")\n",
    "xlabel!(\"Wavenumber (cm⁻¹)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "#### Now let's think about the forward model close to the linearisation point (as this one here is non-linear)\n",
    "$$ y = F(x) = F(x_a) + K\\underbrace{(x-x_a)}_{x'}$$\n",
    "$$ \\underbrace{y-F(x_a)}_{y'} = Kx' $$\n",
    "solve, then\n",
    "$$ x = x'+x_a $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝐱a = [vmr_co2; vmr_h2o; vmr_ch4; p[:] ];\n",
    "𝐱 = [vmr_co2; vmr_h2o; vmr_ch4; p[:] ];\n",
    "ind_change = 62\n",
    "𝐱[ind_change] = 0.0005\n",
    "@show 𝐱[ind_change]\n",
    "@show profile_caltech_hr.p[ind_change]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR   = 2000.0\n",
    "noise = 2.0/SNR\n",
    "y_xa  = forward_model_x(𝐱a);\n",
    "ϵ  = noise * randn.(length(y_xa));\n",
    "y_x   = forward_model_x(𝐱) .+ ϵ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tccon.ν_out, y_xa)\n",
    "plot!(tccon.ν_out, y_x)\n",
    "#xlims!(6322.8,6323.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime = y_x - y_xa;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get K evaluated at xa\n",
    "@time ForwardDiff.jacobian!(result, forward_model_x, 𝐱a );\n",
    "K = DiffResults.jacobian(result);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Naive fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "Se = Diagonal((ones(length(tccon.ν_out)).*noise).^2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prime = inv(K'inv(Se)K)K'inv(Se)* y_prime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x̂_naive = x_prime + 𝐱a;\n",
    "@show nL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(𝐱a[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"xa\")\n",
    "plot!(𝐱[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"true x\")\n",
    "plot!(x̂_naive[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"retrieved x\")\n",
    "xlabel!(\"CO2 (ppm)\")\n",
    "ylabel!(\"pressure (hPa)\")\n",
    "xlims!(-2000,2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Why is this so bad?\n",
    "Ok, this simple inversion was really bad and messed up the retrieved state vector with many unphysical values. \n",
    "\n",
    "Why did this happen and how can we salvage this? The inversion is unstable (not enough information to solve the state vector) and we need to regularize the problem, a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting. There are different ways of doing this but for now, we will focus on using actual prior information and the Bayes Theorem (see Rodger's, pages 22ff):\n",
    "$$P(x|y) = \\frac{P(y|x)P(x)}{P(y)}$$\n",
    "\n",
    "Using Gaussian uncertainties, we can express mismatches in the measurement space as well as the state vector space, if we assume some prior knowledge as to how the state vector \"should\" behave, characterized by it's prior $x_a$ (mean expected state) as well as its variance-covariance matrix $S_a$:\n",
    "$$-2\\ln P(y|x) = (y-Kx)^T S_{\\epsilon}^{-1}(y-Kx)+c_1$$\n",
    "and \n",
    "$$-2\\ln P(x) =  (x-x_a)^T S_{a}^{-1}(x-x_a)+c_2\\,,$$\n",
    "with the prior covariance matrix $S_a$ representing the expected value \n",
    "$$S_a = \\mathbf{E}\\left((x-x_a)(x-x_a)^T\\right)$$\n",
    "\n",
    "If we assume $P(y)$ to just be a normalising factor, we can rewrite $-2\\ln P(x|y)$ as\n",
    "$$-2\\ln P(x|y) = (y-Kx)^T S_{\\epsilon}^{-1}(y-Kx) + (x-x_a)^T S_{a}^{-1}(x-x_a) + c_3$$\n",
    "\n",
    "If we want to maximize $P(x|y)$, we just have to minimize the right hand side of the equation, which is almost exactly the same we found for the normal least squares approach apart from the added cost function induced by our prior knowledge: $(x-x_a)^T S_{a}^{-1}(x-x_a)$. \n",
    "\n",
    "As shown in Rodgers, the retrieved state vector $\\hat{x}$ is now:\n",
    "$$\\hat{x} = x_a + (K^TS_\\epsilon^{-1}K+S_a^{-1})^{-1}K^TS_\\epsilon^{-1}(y-Kx_a)\\,$$\n",
    "for which we can replace $Kx_a$ with $F(x_a)$ as done in our case. \n",
    "\n",
    "What can we use as prior information for the CO$_2$ mixing ratio now? We know that it is a long-lived gas and its variations are rather small, with an overall seasonal amplitude of only 10-20ppm (around a background of 400ppm). We also know that changes in its concentrations are usually coorelated in between nearby atmospheric layers (vertically). So we could construct some covariance matrix based on a fixed relative errors on the diagonal but adding correlations on the off-diagonal (feel free to play around!). \n",
    "\n",
    "In the example below, we just assume a 10% uncertainty on the diagonal. Later, we could use variances on off-diagonal elements scaled with a exp(-corr_length * dp) factor, which provides a correlation as a function of pressure difference between layers (one could use real model data to try to generate a proper covariance matrix but here we use just this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_state = length(𝐱a);\n",
    "Sa = zeros(n_state,n_state);\n",
    "rel_error = 0.25;\n",
    "for i=1:3*nL\n",
    "    Sa[i,i] = (rel_error*𝐱a[i])^2\n",
    "end\n",
    "for i=3*nL+1:n_state\n",
    "    Sa[i,i] = 1e20;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Computing Posterior error covariance, Gain matrix and Averaging Kernel:\n",
    "We can compute the Gain matrix and posterior error covariance as before, just with $\\hat{S}^{-1}$ now being\n",
    "$$\\hat{S}^{-1} = K^TS_\\epsilon^{-1}K+S_a^{-1}\\,$$\n",
    "(see Rodgers).\n",
    "\n",
    "We can also compute the Averaging Kernel Matrix $A$,\n",
    "$$AK = {\\partial \\hat{x} \\over \\partial x} = GK$$\n",
    "This can be seen as $\\Delta F(x)$ is $K(x-x_a)+\\epsilon$, thus\n",
    "$$\\hat{x} = G[K(x-x_a)+\\epsilon] = GK(x-x_a)+G\\epsilon$$\n",
    "\n",
    "It is important to fully understand the meaning of the A matrix as it is instrumental in understanding the measurement sensitivity and later comparisons against model data (for instance). The A matrix (nxn) represents the derivative of the retrieved state vector $\\hat{x}$ with respect to a true change in the state vector $x$. E.g. we can solve the question what would happen to the state vector if CO$_2$ in reality changes at only one layer at say 800hPa or 300hPa.\n",
    "$$A = {\\partial \\hat{x} \\over \\partial x} = \\left\\vert\\matrix{{\\partial \\hat{x}_1 \\over \\partial x_1} & {\\dots} & {\\partial \\hat{x}_1 \\over \\partial x_n} \\cr \n",
    "{\\vdots} & {\\ddots } & {\\vdots} \\cr \n",
    "{\\partial \\hat{x}_n \\over \\partial x_1} & {\\dots} & {\\partial \\hat{x}_n \\over \\partial x_n}}\\right\\vert\\,.$$\n",
    "\n",
    "The rows of the $A$ basically show how a specific retrieved state vector element $\\hat{x}_i$ reacts to true changes of the state vector at different positions $x_i$ while the columns of the $A$ show how the overal state vector $\\hat{x}$ reacts to a perturbation of the true state in one singular position $x_i$. This is reflected in the columns of the $A$ while the rows reflect the change in the retrieved state vector at particular index $i$ vs. a change in the true state at all other positions. \n",
    "In the ideal case, the $A$ would be unity on the diagonal and zero elsewhere, indicating a perfect retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "So, let's compute the posterior covariance matrix S^hat, the Gain Matrix G and the Averaging Kernel Matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain Matrix:\n",
    "G = inv(K'inv(Se)K + inv(Sa))K'inv(Se)\n",
    "# Averaging Kernel Matrix A\n",
    "A = G*K;\n",
    "Ŝ = inv(K'inv(Se)K + inv(Sa))\n",
    "x_primeBayes = G * y_prime;\n",
    "x̂_bayes = x_primeBayes + 𝐱a;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model response to noise vector\n",
    "# Retrieval noise:\n",
    "Geps = G*ϵ;\n",
    "\n",
    "# Smoothing Error\n",
    "A_smooth = (A-I)*(𝐱-𝐱a);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's look at averaging kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(A[1:nL,:],profile_caltech_hr.p/100, yaxis=:flip, lw=2, legend = false)\n",
    "xlims!(-0.25,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look a bit \"wonky\" but in our case, it has to do with the fact that the layers have different dry masses, let's normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(A[1:nL,:]./profile_caltech_hr.vcd_dry * mean(profile_caltech_hr.vcd_dry),profile_caltech_hr.p/100, yaxis=:flip, lw=2, legend = false)\n",
    "xlims!(-0.25,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just plot a subset:\n",
    "plot(A[1:nL,50]./profile_caltech_hr.vcd_dry * mean(profile_caltech_hr.vcd_dry),profile_caltech_hr.p/100, yaxis=:flip, lw=2, legend = false)\n",
    "plot!(A[1:nL,nL]./profile_caltech_hr.vcd_dry * mean(profile_caltech_hr.vcd_dry),profile_caltech_hr.p/100, yaxis=:flip, lw=2, legend = false)\n",
    "xlims!(-0.25,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error characterization:\n",
    "Let's look at the impact of the smoothing error and retrieval noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(𝐱a[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"xa\")\n",
    "plot!(𝐱[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"true x\")\n",
    "plot!((x̂_bayes[1:nL])*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"retrieved x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's separate the error terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(𝐱a[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"xa\")\n",
    "#plot!(𝐱[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"true x\")\n",
    "plot((x̂_bayes[1:nL]-𝐱[1:nL] )*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"retrieval total error\")\n",
    "plot!((G*ϵ)[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"Retrieval Noise: G*eps\")\n",
    "plot!( 1.e6*(A_smooth[1:nL]) ,profile_caltech_hr.p/100,lw=2, label=\"Smoothing error (A-I)(x-xa)\")\n",
    "#plot!( 1e6*(x̂_bayes[1:nL]-Geps[1:nL]),profile_caltech_hr.p/100,yflip=true,label=\"xhat - G*eps\")\n",
    "xlabel!(\"CO2 (ppm) error\")\n",
    "ylabel!(\"pressure (hPa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(𝐱a[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"xa\")\n",
    "plot!(𝐱[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"true x\")\n",
    "plot!(x̂_bayes[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"retrieved x\")\n",
    "plot!(𝐱a[1:nL]*1e6 + (G*ϵ)[1:nL]*1e6 ,profile_caltech_hr.p/100, yaxis=:flip, lw=2, label=\"xa + G*eps\")\n",
    "#plot!( 1.e6*(A_smooth[1:nL] + 𝐱a[1:nL]) ,profile_caltech_hr.p/100,lw=2, label=\"Smoothing error + xa\")\n",
    "plot!( 1e6*(x̂_bayes[1:nL]-Geps[1:nL]),profile_caltech_hr.p/100,yflip=true,label=\"xhat - G*eps\")\n",
    "xlabel!(\"CO2 (ppm)\")\n",
    "ylabel!(\"pressure (hPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Degrees of freedom for CO$_2$ profile\n",
    "The degrees of freedom for signal (DOFs) is a metric for how many independent variables one can actually retrieve. It can be computed at the trace of the averaging kernel matrix. (see e.g. Rodgers, page 54 top)\n",
    "\n",
    "Here, we can just look at the DOF for the CO2 retrievals (or the other trace gases). The is the trace of the averaging kernel matrix over the CO$_2$ state vector elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Printf\n",
    "# CO2\n",
    "println(\"DOF for CO2: \", @sprintf \"%1.1f\" tr(A[1:nL,1:nL]))\n",
    "# CH4\n",
    "println(\"DOF for CH4: \", @sprintf \"%1.1f\" tr(A[nL+1:2nL,nL+1:2nL]))\n",
    "# H2O\n",
    "println(\"DOF for H2O: \", @sprintf \"%1.1f\" tr(A[2nL+1:3nL,2nL+1:3nL]))\n",
    "\n",
    "# Entire state vector:\n",
    "println(\"DOF for X: \",@sprintf \"%1.1f\" tr(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column averaging kernel\n",
    "\n",
    "Often, we are not really interested in the entire state vector itself but derived properties using linear operators, for instance the column averaged mixing ratio of CO2, denoted as XCO2 (basically the column amount of CO2 divided by the column amount of dry air).\n",
    "\n",
    "We can define an operator h, which let's us compute the column averaged mixing ratio from the state vector CO$_2$ elements.\n",
    "$$XCO_2 = h^T\\hat{x}$$\n",
    "In our case, h is just the mass-weighted contribution of each layer to the total column. It is \n",
    "$$ h = VCD_{dry}/\\sum{VCD_{dry}}$$\n",
    "\n",
    "With the averaging kernel $A$ as described above, we can compute \n",
    "$$ \\frac{\\partial XCO_2}{\\partial x_j} = (h^TA)_j$$\n",
    "\n",
    "The column averaging kernel $cAK$ can then be computed as well, which is \n",
    "$$ cA_j = \\frac{\\partial XCO_2}{\\partial XCO2_j} = \\frac{\\partial XCO_2}{\\partial x_j \\cdot h_j} = (h^TA)_j/h_j$$\n",
    "\n",
    "And the variance in XCO$_2$ is given by \n",
    "$$\\sigma^2(XCO_2) = h^T\\hat{S}h$$\n",
    "\n",
    "You can read up on random variables and transformations here: ftp://fluo.gps.caltech.edu/XYZT_ESE156/Reading/RandomVectors.pdf)\n",
    "\n",
    "Assume you have a random variable vector $g$ (dimension P) with covariance $S_g$. If you convert $g$ into a new random variable vector $k$ (dimension Q) using the linear transform $M$ (a QxP matrix):\n",
    "$$k = Mg\\,,$$\n",
    "then the covariance of $k$ ($S_k$) is \n",
    "$$S_k = MS_gM^T$$\n",
    "\n",
    "You could use this equation for instance to proof that the error in the mean of uncorrelated errors goes down with $1/\\sqrt(n)$ but not at all if errors are fully correlated. If you remember this one equation, it will remain very useful and is also the principle behind all the column averaging property calculations above for which we use the weighting function $h$ to convert a `n` dimensional random variable in the state vector to a 1D column averaged mixing ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column averaging Operator for CO2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_co2 = zeros(length(𝐱))\n",
    "h_co2[1:nL] = profile_caltech_hr.vcd_dry / sum(profile_caltech_hr.vcd_dry);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show h_co2' * x̂_bayes * 1e6\n",
    "@show h_co2' * 𝐱a      * 1e6\n",
    "@show h_co2' * 𝐱       * 1e6\n",
    "@show h_co2' * x̂_naive * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show sqrt(h_co2' * Sa * h_co2) * 1e6\n",
    "@show sqrt(h_co2' * Ŝ  * h_co2) * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column Averaging Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cK = (h_co2'*A)[1,:]./h_co2\n",
    "\n",
    "plot(cK[1:nL],profile_caltech_hr.p/100,yflip=true,lw=2, label=\"cAK for CO2\")\n",
    "\n",
    "xlabel!(\"Column averaging kernel\")\n",
    "ylabel!(\"Pressure [hPa]\")\n",
    "title!(\"Column averaging kernel for CO2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change Sa to something different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
